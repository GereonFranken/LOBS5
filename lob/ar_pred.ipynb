{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# load test data (messages & book)\n",
    "# select (random) test sequence\n",
    "# encode msg and book sequence for model\n",
    "\n",
    "# get raw book data (L2) at the start of the sequence\n",
    "# init simulator with initial book\n",
    "# replay sequence in simulator (actual)\n",
    "\n",
    "# load trained model\n",
    "# predict next message\n",
    "# map message to one the simulator understands & is valid\n",
    "# apply message to simulator (predicted)\n",
    "# get L2 representation and encode it for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as jnp\n",
    "from jax.nn import one_hot\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from typing import Union\n",
    "import time\n",
    "from typing import Optional, Union\n",
    "\n",
    "from lob_seq_model import LobPredModel\n",
    "from encoding import Vocab, Message_Tokenizer\n",
    "from lobster_dataloader import LOBSTER_Dataset, LOBSTER_Subset, LOBSTER_Sampler, LOBSTER\n",
    "import preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/nfs/home/peern/LOBS5/data/raw/'\n",
    "#save_dir = '/nfs/home/peern/LOBS5/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_files = sorted(glob(data_dir + '*message*.csv'))\n",
    "book_files = sorted(glob(data_dir + '*orderbook*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/peern/rlenv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/nfs/home/peern/rlenv/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# load test data (last day)\n",
    "\n",
    "m = pd.read_csv(\n",
    "    message_files[-1],\n",
    "    names=['time', 'event_type', 'order_id', 'size', 'price', 'direction'],\n",
    "    index_col=False)\n",
    "\n",
    "b = pd.read_csv(\n",
    "    book_files[-1],\n",
    "    index_col=False,\n",
    "    header=None\n",
    ")\n",
    "\n",
    "# remove diallowed order types\n",
    "m = m.loc[m.event_type.isin([1, 2, 3, 4])]\n",
    "b = b.loc[m.index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book encoding\n",
    "price_levels = 40  # how many ticks to represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message encoding\n",
    "v = Vocab()\n",
    "tok = Message_Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< pre processing >>\n",
      "truncating 0.0000% of prices > 9900\n",
      "truncating 0.0000% of prices < -9900\n",
      "<< encoding >>\n"
     ]
    }
   ],
   "source": [
    "print('<< pre processing >>')\n",
    "m_proc = tok.preproc(m, b)\n",
    "print('<< encoding >>')\n",
    "m_enc = tok.encode(m_proc, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first message from raw data as well\n",
    "m = m.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    3,     3,     8, ...,     2,     2,     2],\n",
       "       [    3,     3,     8, ...,     2,     2,     2],\n",
       "       [    3,     3,     9, ...,     2,     2,     2],\n",
       "       ...,\n",
       "       [   26,   402,   997, ..., 11108, 11007, 11110],\n",
       "       [   26,   402,   985, ..., 11108, 11010, 11110],\n",
       "       [   26,   402,  1002, ...,     2,     2,     2]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829106, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829106, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_proc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829106, 20)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load from saved file instead\n",
    "b_enc = preproc.process_book(b, price_levels=price_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829107, 40)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829107, 41)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_messages = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when to start the prediction\n",
    "# convert time into seconds after midnight\n",
    "start_time = (pd.to_datetime('11:00') - pd.to_datetime('00:00')).total_seconds()\n",
    "# get seq end index\n",
    "end_i = len(m.loc[m.time < start_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_seq = m_enc[end_i - n_messages : end_i].reshape(-1)  # (n_messages [500] * levels [20], )\n",
    "b_seq = b_enc[end_i - n_messages : end_i]              # (n_messages [500], price_levels + 1 [41])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add git submodule to path to allow imports to work\n",
    "submodule_name = 'AlphaTrade'\n",
    "(parent_folder_path, current_dir) = os.path.split(os.path.abspath(''))\n",
    "sys.path.append(os.path.join(parent_folder_path, submodule_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnax_exchange.jaxob.jorderbook import OrderBook\n",
    "import gymnax_exchange.jaxob.JaxOrderbook as job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: integrate this into simualtor: OrderBook\n",
    "\n",
    "def init_msgs_from_l2(book: Union[pd.Series, onp.ndarray]) -> jnp.ndarray:\n",
    "    orderbookLevels = len(book) // 4  # price/quantity for bid/ask\n",
    "    data = jnp.array(book).reshape(int(orderbookLevels*2),2)\n",
    "    newarr = jnp.zeros((int(orderbookLevels*2),8))\n",
    "    initOB = newarr \\\n",
    "        .at[:,3].set(data[:,0]) \\\n",
    "        .at[:,2].set(data[:,1]) \\\n",
    "        .at[:,0].set(1) \\\n",
    "        .at[0:orderbookLevels*4:2,1].set(-1) \\\n",
    "        .at[1:orderbookLevels*4:2,1].set(1) \\\n",
    "        .at[:,4].set(0) \\\n",
    "        .at[:,5].set(job.INITID) \\\n",
    "        .at[:,6].set(34200) \\\n",
    "        .at[:,7].set(0).astype('int32')\n",
    "    return initOB\n",
    "\n",
    "def msgs_to_jnp(m_df: pd.DataFrame) -> jnp.ndarray:\n",
    "    m_df = m_df.copy()\n",
    "    cols = ['Time', 'Type', 'OrderID', 'Quantity', 'Price', 'Side']\n",
    "    if m_df.shape[1] == 7:\n",
    "        cols += [\"TradeID\"]\n",
    "    m_df.columns = cols\n",
    "    m_df['TradeID'] = 0  #  TODO: should be TraderID for multi-agent support\n",
    "    col_order=['Type','Side','Quantity','Price','TradeID','OrderID','Time']\n",
    "    m_df = m_df[col_order]\n",
    "    m_df = m_df[(m_df['Type'] != 6) & (m_df['Type'] != 7) & (m_df['Type'] != 5)]\n",
    "    time = m_df[\"Time\"].astype('string').str.split('.',expand=True)\n",
    "    m_df[[\"TimeWhole\",\"TimeDec\"]] = time.astype('int32')\n",
    "    m_df = m_df.drop(\"Time\", axis=1)\n",
    "    mJNP = jnp.array(m_df)\n",
    "    return mJNP\n",
    "\n",
    "def reset_orderbook(\n",
    "        b: OrderBook,\n",
    "        l2_book: Optional[Union[pd.Series, onp.ndarray]] = None,\n",
    "    ) -> None:\n",
    "    b.orderbook_array = b.orderbook_array.at[:].set(-1)\n",
    "    if l2_book is not None:\n",
    "        msgs = init_msgs_from_l2(l2_book)\n",
    "        b.process_orders_array(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gymnax_exchange.jaxob.jorderbook.OrderBook at 0x7f216409d700>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = OrderBook(price_levels=10, orderQueueLen=20)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init simulator at the start of the sequence\n",
    "reset_orderbook(sim, b.iloc[end_i - n_messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay sequence in simulator (actual)\n",
    "# so that sim is at the same state as the model\n",
    "replay = msgs_to_jnp(m.iloc[end_i - n_messages : end_i])\n",
    "trades = sim.process_orders_array(replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([988000,    100, 987900,    802, 988100,    182, 987800,    782,\n",
       "       988200,   1056, 987700,    600, 988300,    706, 987600,    500,\n",
       "       988400,   1100, 987500,   1250, 988500,   1012, 987400,    850,\n",
       "       988600,    468, 987300,    490, 988700,   1615, 987200,     50,\n",
       "       988800,    431, 987100,    750, 989000,     50, 987000,     50],      dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.get_L2_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "#os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".25\"\n",
    "import torch\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from glob import glob\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "from jax.scipy.linalg import block_diag\n",
    "from flax.training import checkpoints\n",
    "import orbax\n",
    "\n",
    "#from lob.lob_seq_model import BatchLobPredModel\n",
    "from lob.train_helpers import create_train_state, eval_step, prep_batch, cross_entropy_loss, compute_accuracy\n",
    "from s5.ssm import init_S5SSM\n",
    "from s5.ssm_init import make_DPLR_HiPPO\n",
    "from s5.dataloading import make_data_loader\n",
    "from lob.lobster_dataloader import LOBSTER_Dataset, LOBSTER\n",
    "\n",
    "import validation_helpers as valh\n",
    "from lob.init_train import init_train_state, load_checkpoint, load_args_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary for checkpoints to be loaded in jupyter notebook\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = load_args_from_checkpoint('../checkpoints_book_causal/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(C_init='trunc_standard_normal', USE_WANDB=True, activation_fn='half_glu1', batchnorm=True, bidirectional=False, blocks=8, bn_momentum=0.95, bsz=16, clip_eigs=False, conj_sym=True, cosine_anneal=True, d_model=32, dataset='lobster-prediction', dir_name='./data', discretization='zoh', dt_global=False, dt_max=0.1, dt_min=0.001, early_stop_patience=1000, epochs=100, jax_seed=1919, lr_factor=1.0, lr_min=0, lr_patience=1000000, masking='causal', mode='pool', n_layers=6, opt_config='standard', p_dropout=0.0, prenorm=True, reduce_factor=1.0, ssm_lr_base=0.0005, ssm_size_base=32, use_book_data=True, wandb_entity='peer-nagy', wandb_project='LOBS5', warmup_end=1, weight_decay=0.05)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vocab()\n",
    "n_classes = len(v)\n",
    "seq_len = n_messages * Message_Tokenizer.MSG_LEN\n",
    "book_dim = b_enc.shape[1]\n",
    "book_seq_len = n_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring standard optimization setup\n",
      "[*] Trainable Parameters: 1094460\n"
     ]
    }
   ],
   "source": [
    "new_train_state = init_train_state(\n",
    "    args,\n",
    "    n_classes=n_classes,\n",
    "    seq_len=seq_len,\n",
    "    book_dim=book_dim,\n",
    "    book_seq_len=book_seq_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = load_checkpoint(\n",
    "    new_train_state,\n",
    "    '../checkpoints_book_causal/',\n",
    "    args.__dict__)\n",
    "state = ckpt['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return model_cls from init fn?\n",
    "model = model_cls(training=False, step_rescale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO from above:\n",
    "# x load trained model\n",
    "#   predict next message\n",
    "#   map message to one the simulator understands & is valid\n",
    "#   apply message to simulator (predicted)\n",
    "#   get L2 representation and encode it for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactor slightly and work in simulation step\n",
    "#       and simulator matching orders\n",
    "\n",
    "pred_n_messages = 1\n",
    "valid_mask_array = valh.syntax_validation_matrix()\n",
    "inf_seq = valh.pred_msg(\n",
    "    start_seq,\n",
    "    pred_n_messages,\n",
    "    state,\n",
    "    model,\n",
    "    args.batchnorm,\n",
    "    rng,\n",
    "    valid_mask_array\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

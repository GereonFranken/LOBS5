{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTENTS\n",
    "\n",
    "# load test data (messages & book)\n",
    "# select (random) test sequence\n",
    "# encode msg and book sequence for model\n",
    "\n",
    "# get raw book data (L2) at the start of the sequence\n",
    "# init simulator with initial book\n",
    "# replay sequence in simulator (actual)\n",
    "\n",
    "# load trained model\n",
    "# predict next message\n",
    "# map message to one the simulator understands & is valid\n",
    "# apply message to simulator (predicted)\n",
    "# get L2 representation and encode it for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "#os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".25\"\n",
    "import torch\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from glob import glob\n",
    "import numpy as onp\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from typing import Union, Optional\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.nn import one_hot\n",
    "from jax import random\n",
    "from jax.scipy.linalg import block_diag\n",
    "from flax.training import checkpoints\n",
    "import orbax\n",
    "\n",
    "#from lob.lob_seq_model import BatchLobPredModel\n",
    "from lob.train_helpers import create_train_state, eval_step, prep_batch, cross_entropy_loss, compute_accuracy\n",
    "from s5.ssm import init_S5SSM\n",
    "from s5.ssm_init import make_DPLR_HiPPO\n",
    "from s5.dataloading import make_data_loader\n",
    "from lob_seq_model import LobPredModel\n",
    "from encoding import Vocab, Message_Tokenizer\n",
    "from lobster_dataloader import LOBSTER_Dataset, LOBSTER_Subset, LOBSTER_Sampler, LOBSTER\n",
    "\n",
    "import preproc\n",
    "import validation_helpers as valh\n",
    "from lob.init_train import init_train_state, load_checkpoint, load_args_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/nfs/home/peern/LOBS5/data/raw/'\n",
    "save_dir = '/nfs/home/peern/LOBS5/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_files = sorted(glob(data_dir + '*message*.csv'))\n",
    "book_files = sorted(glob(data_dir + '*orderbook*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/peern/rlenv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/nfs/home/peern/rlenv/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# load test data (last day)\n",
    "\n",
    "m = pd.read_csv(\n",
    "    message_files[-1],\n",
    "    names=['time', 'event_type', 'order_id', 'size', 'price', 'direction'],\n",
    "    index_col=False)\n",
    "\n",
    "b = pd.read_csv(\n",
    "    book_files[-1],\n",
    "    index_col=False,\n",
    "    header=None\n",
    ")\n",
    "\n",
    "# remove diallowed order types\n",
    "m = m.loc[m.event_type.isin([1, 2, 3, 4])]\n",
    "b = b.loc[m.index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book encoding\n",
    "price_levels = 40  # how many ticks to represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message encoding\n",
    "v = Vocab()\n",
    "tok = Message_Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode from raw data\n",
    "\n",
    "# print('<< pre processing >>')\n",
    "# m_proc = tok.preproc(m, b)\n",
    "# print('<< encoding >>')\n",
    "# m_enc = tok.encode(m_proc, v)\n",
    "\n",
    "# instead load from file:\n",
    "msg_enc_file = sorted(glob(save_dir + '*message*.npy'))[-1]\n",
    "m_enc = onp.load(msg_enc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first message from raw data as well\n",
    "m = m.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    3,     3,     8, ...,     2,     2,     2],\n",
       "       [    3,     3,     8, ...,     2,     2,     2],\n",
       "       [    3,     3,     9, ...,     2,     2,     2],\n",
       "       ...,\n",
       "       [   26,   402,   997, ..., 11108, 11007, 11110],\n",
       "       [   26,   402,   985, ..., 11108, 11010, 11110],\n",
       "       [   26,   402,  1002, ...,     2,     2,     2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829106, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_proc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829106, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode from raw data:\n",
    "# b_enc = preproc.process_book(b, price_levels=price_levels)\n",
    "\n",
    "# instead load from file:\n",
    "book_enc_file = sorted(glob(save_dir + '*book*.npy'))[-1]\n",
    "b_enc = onp.load(book_enc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_enc_ = preproc.process_book(b, price_levels=price_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829107, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829107, 41)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_enc_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_messages = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when to start the prediction\n",
    "# convert time into seconds after midnight\n",
    "start_time = (pd.to_datetime('11:00') - pd.to_datetime('00:00')).total_seconds()\n",
    "# get seq end index\n",
    "end_i = len(m.loc[m.time < start_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_seq = m_enc[end_i - n_messages : end_i].reshape(-1)  # (n_messages [500] * levels [20], )\n",
    "# book state: we already include the book state after the last message\n",
    "# (different to training where we only have the book state before the first message\n",
    "# and mask part of the last message)\n",
    "# for message seq, we first need to append an empty message\n",
    "b_seq = b_enc[end_i - n_messages + 1 : end_i + 1]      # (n_messages [500], price_levels + 1 [41])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add git submodule to path to allow imports to work\n",
    "submodule_name = 'AlphaTrade'\n",
    "(parent_folder_path, current_dir) = os.path.split(os.path.abspath(''))\n",
    "sys.path.append(os.path.join(parent_folder_path, submodule_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnax_exchange.jaxob.jorderbook import OrderBook\n",
    "import gymnax_exchange.jaxob.JaxOrderbook as job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: integrate this into simualtor: OrderBook\n",
    "\n",
    "def init_msgs_from_l2(book: Union[pd.Series, onp.ndarray]) -> jnp.ndarray:\n",
    "    orderbookLevels = len(book) // 4  # price/quantity for bid/ask\n",
    "    data = jnp.array(book).reshape(int(orderbookLevels*2),2)\n",
    "    newarr = jnp.zeros((int(orderbookLevels*2),8))\n",
    "    initOB = newarr \\\n",
    "        .at[:,3].set(data[:,0]) \\\n",
    "        .at[:,2].set(data[:,1]) \\\n",
    "        .at[:,0].set(1) \\\n",
    "        .at[0:orderbookLevels*4:2,1].set(-1) \\\n",
    "        .at[1:orderbookLevels*4:2,1].set(1) \\\n",
    "        .at[:,4].set(0) \\\n",
    "        .at[:,5].set(job.INITID) \\\n",
    "        .at[:,6].set(34200) \\\n",
    "        .at[:,7].set(0).astype('int32')\n",
    "    return initOB\n",
    "\n",
    "def msgs_to_jnp(m_df: pd.DataFrame) -> jnp.ndarray:\n",
    "    m_df = m_df.copy()\n",
    "    cols = ['Time', 'Type', 'OrderID', 'Quantity', 'Price', 'Side']\n",
    "    if m_df.shape[1] == 7:\n",
    "        cols += [\"TradeID\"]\n",
    "    m_df.columns = cols\n",
    "    m_df['TradeID'] = 0  #  TODO: should be TraderID for multi-agent support\n",
    "    col_order=['Type','Side','Quantity','Price','TradeID','OrderID','Time']\n",
    "    m_df = m_df[col_order]\n",
    "    m_df = m_df[(m_df['Type'] != 6) & (m_df['Type'] != 7) & (m_df['Type'] != 5)]\n",
    "    time = m_df[\"Time\"].astype('string').str.split('.',expand=True)\n",
    "    m_df[[\"TimeWhole\",\"TimeDec\"]] = time.astype('int32')\n",
    "    m_df = m_df.drop(\"Time\", axis=1)\n",
    "    mJNP = jnp.array(m_df)\n",
    "    return mJNP\n",
    "\n",
    "def reset_orderbook(\n",
    "        b: OrderBook,\n",
    "        l2_book: Optional[Union[pd.Series, onp.ndarray]] = None,\n",
    "    ) -> None:\n",
    "    b.orderbook_array = b.orderbook_array.at[:].set(-1)\n",
    "    if l2_book is not None:\n",
    "        msgs = init_msgs_from_l2(l2_book)\n",
    "        b.process_orders_array(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gymnax_exchange.jaxob.jorderbook.OrderBook at 0x7fbe21de0100>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = OrderBook(price_levels=10, orderQueueLen=20)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init simulator at the start of the sequence\n",
    "reset_orderbook(sim, b.iloc[end_i - n_messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay sequence in simulator (actual)\n",
    "# so that sim is at the same state as the model\n",
    "replay = msgs_to_jnp(m.iloc[end_i - n_messages : end_i])\n",
    "trades = sim.process_orders_array(replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([988000,    100, 987900,    802, 988100,    182, 987800,    782,\n",
       "       988200,   1056, 987700,    600, 988300,    706, 987600,    500,\n",
       "       988400,   1100, 987500,   1250, 988500,   1012, 987400,    850,\n",
       "       988600,    468, 987300,    490, 988700,   1615, 987200,     50,\n",
       "       988800,    431, 987100,    750, 989000,     50, 987000,     50],      dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.get_L2_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary for checkpoints to be loaded in jupyter notebook\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = load_args_from_checkpoint('../checkpoints_book_causal_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(C_init='trunc_standard_normal', USE_WANDB=True, activation_fn='half_glu1', batchnorm=True, bidirectional=False, blocks=8, bn_momentum=0.95, bsz=16, clip_eigs=False, conj_sym=True, cosine_anneal=True, d_model=32, dataset='lobster-prediction', dir_name='./data', discretization='zoh', dt_global=False, dt_max=0.1, dt_min=0.001, early_stop_patience=1000, epochs=100, jax_seed=42, lr_factor=1.0, lr_min=0, lr_patience=1000000, masking='causal', mode='pool', n_layers=6, opt_config='standard', p_dropout=0.0, prenorm=True, reduce_factor=1.0, ssm_lr_base=0.0005, ssm_size_base=32, use_book_data=True, wandb_entity='peer-nagy', wandb_project='LOBS5', warmup_end=1, weight_decay=0.05)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vocab()\n",
    "n_classes = len(v)\n",
    "seq_len = n_messages * Message_Tokenizer.MSG_LEN\n",
    "book_dim = b_enc.shape[1]\n",
    "book_seq_len = n_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring standard optimization setup\n",
      "[*] Trainable Parameters: 1094460\n"
     ]
    }
   ],
   "source": [
    "new_train_state, model_cls = init_train_state(\n",
    "    args,\n",
    "    n_classes=n_classes,\n",
    "    seq_len=seq_len,\n",
    "    book_dim=book_dim,\n",
    "    book_seq_len=book_seq_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = load_checkpoint(\n",
    "    new_train_state,\n",
    "    '../checkpoints_book_causal_2/',\n",
    "    args.__dict__)\n",
    "state = ckpt['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cls(training=False, step_rescale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO from above:\n",
    "# x load trained model\n",
    "#   predict next message\n",
    "#   map message to one the simulator understands & is valid\n",
    "#   apply message to simulator (predicted)\n",
    "#   get L2 representation and encode it for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new HID message (and next LOB state if not already in seq)\n",
    "# loop: predict next token until full message is generated\n",
    "# map message to one the simulator understands & is valid\n",
    "# feed message to simulator (predicted) --> next book state\n",
    "# encode next book state for model and append to book sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    8,   402,    38, ..., 11107, 11009, 11109])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(v)\n",
    "batchnorm = args.batchnorm\n",
    "sample_top_n = 1\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, rng_ = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_obj = LOBSTER(\n",
    "    'lobster',\n",
    "    data_dir='/nfs/home/peern/LOBS5/data/',\n",
    "    mask_fn=LOBSTER_Dataset.causal_mask,\n",
    "    use_book_data=True,\n",
    ")\n",
    "dataset_obj.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = make_data_loader(\n",
    "    dataset_obj.dataset_test,\n",
    "    dataset_obj,\n",
    "    seed=args.jax_seed,\n",
    "    batch_size=args.bsz,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "tok = Message_Tokenizer()\n",
    "\n",
    "all_pred_toks = []\n",
    "all_labels = []\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "ranks = []\n",
    "valid_mass = []\n",
    "valid_mass_n5 = []\n",
    "valid_pred = []\n",
    "losses_baseline = []\n",
    "\n",
    "VALID_MATRIX = valh.syntax_validation_matrix()\n",
    "\n",
    "for batch_idx, batch in enumerate(test_loader):\n",
    "    \n",
    "    # PREPARE BATCH\n",
    "    inputs, labels, integration_timesteps = prep_batch(batch, seq_len, n_classes)\n",
    "    # INFERENCE STEP\n",
    "    loss, acc, pred = eval_step(\n",
    "        inputs, labels, integration_timesteps, state, model, args.batchnorm)\n",
    "    \n",
    "    # STORE RESULTS\n",
    "    pred_toks = pred.argmax(axis=-1)\n",
    "    all_labels += labels.tolist()\n",
    "    all_pred_toks += pred_toks.tolist()\n",
    "    \n",
    "    # STATS\n",
    "    losses.append(cross_entropy_loss(pred, labels))\n",
    "    accuracy.append(compute_accuracy(pred, labels))\n",
    "    \n",
    "    # where does the correct label rank in the predicted distribution?\n",
    "    ranks.append(valh.pred_rank(pred, labels))\n",
    "    # how much of the predicted distribution is valid?\n",
    "    masked_fields = valh.get_masked_fields(batch[0])\n",
    "    valid_mass.append(valh.valid_prediction_mass(pred, masked_fields))\n",
    "    valid_mass_n5.append(valh.valid_prediction_mass(pred, masked_fields, top_n=5))\n",
    "\n",
    "    # check if argmax prediction is valid token for masked fields\n",
    "    valid_pred.append(valh.is_tok_valid(pred_toks, masked_fields, v))\n",
    "\n",
    "    # benchmark: uniform prediction over syntactically valid tokens\n",
    "    pos = valh.get_masked_idx(batch[0])[..., -1]\n",
    "    baseline_distr = VALID_MATRIX[pos] / VALID_MATRIX[pos].sum(axis=-1, keepdims=True)\n",
    "    losses_baseline.append(cross_entropy_loss(jnp.log(\n",
    "            jnp.where(baseline_distr==0, 1e-10, baseline_distr)\n",
    "        ), labels)\n",
    "    )\n",
    "\n",
    "all_labels = jnp.array(all_labels)\n",
    "all_pred_toks = jnp.array(all_pred_toks)\n",
    "losses = jnp.array(losses)\n",
    "accuracy = jnp.array(accuracy)\n",
    "ranks = jnp.array(ranks)\n",
    "valid_mass = jnp.array(valid_mass)\n",
    "valid_mass_n5 = jnp.array(valid_mass_n5)\n",
    "valid_pred = jnp.array(valid_pred)\n",
    "losses_baseline = jnp.array(losses_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3042522/1293698468.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'median rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean valid mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_mass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "print('mean loss', losses.mean())\n",
    "print('mean accuracy', accuracy.mean())\n",
    "print('mean rank', ranks.mean())\n",
    "print('median rank', np.median(ranks))\n",
    "print('mean valid mass', valid_mass.mean())\n",
    "print('mean valid mass (top 5)', valid_mass_n5.mean())\n",
    "print('mean valid prediction', valid_pred.mean())\n",
    "print('mean baseline loss (uniform over valid syntax)', losses_baseline.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('precision: {}'.format(precision))\\nprint('recall: {}'.format(recall))\\nprint('fscore: {}'.format(fscore))\\nprint('support: {}'.format(support))\\n\""
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as onp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "    all_labels.astype(int),\n",
    "    all_pred_toks,\n",
    "    labels=range(len(v)),\n",
    "    zero_division=0,\n",
    "    average=None\n",
    ")\n",
    "\n",
    "'''\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_dec = onp.array([(field, dec) for tok, (field, dec) in sorted(v.DECODING_GLOBAL.items())])\n",
    "\n",
    "scores_df = pd.DataFrame({\n",
    "    'field': field_dec[:, 0],\n",
    "    'decoded': field_dec[:, 1],\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'fscore': fscore,\n",
    "    'support': support,\n",
    "})\n",
    "#scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>direction</th>\n",
       "      <td>0.756392</td>\n",
       "      <td>0.509702</td>\n",
       "      <td>0.607549</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_type</th>\n",
       "      <td>0.615834</td>\n",
       "      <td>0.597230</td>\n",
       "      <td>0.605116</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generic</th>\n",
       "      <td>0.713011</td>\n",
       "      <td>0.996881</td>\n",
       "      <td>0.831383</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.401648</td>\n",
       "      <td>0.383298</td>\n",
       "      <td>0.377822</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>0.122625</td>\n",
       "      <td>0.066499</td>\n",
       "      <td>0.078992</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.050324</td>\n",
       "      <td>0.061767</td>\n",
       "      <td>0.052441</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            precision    recall    fscore  support\n",
       "field                                             \n",
       "direction    0.756392  0.509702  0.607549      531\n",
       "event_type   0.615834  0.597230  0.605116      520\n",
       "generic      0.713011  0.996881  0.831383      962\n",
       "price        0.401648  0.383298  0.377822      553\n",
       "size         0.122625  0.066499  0.078992      536\n",
       "time         0.050324  0.061767  0.052441      546"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.loc[scores_df.support > 0].groupby('field').agg(\n",
    "    precision=('precision', 'mean'),\n",
    "    recall=('recall', 'mean'),\n",
    "    fscore=('fscore', 'mean'),\n",
    "    support=('support', 'sum'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_seq_start = m_seq.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_seq = m_seq_start.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    8,   402,   871,   741,   414,  1003,  1032, 11107, 11010,\n",
       "       11109,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     8,   402,   426,   552,   519,  1003,  1107,\n",
       "       11107, 11009, 11109,     8,   402,   938,   659,   860,  1005,\n",
       "        1107, 11107, 11009, 11109])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_seq[-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "\n",
    "valid_mask_array = valh.syntax_validation_matrix(v)\n",
    "\n",
    "m_seq = valh.append_hid_msg(m_seq)\n",
    "\n",
    "#idx = range(Message_Tokenizer.MSG_LEN)\n",
    "reversed_idx = [i \\\n",
    "   for field_i in reversed(list(range(len(Message_Tokenizer.FIELDS)))) \\\n",
    "   for i in range(*LOBSTER_Dataset._get_tok_slice_i(field_i))]\n",
    "\n",
    "for mask_i in reversed_idx:\n",
    "    # syntactically valid tokens for current message position\n",
    "    valid_mask = valid_mask_array[mask_i]\n",
    "\n",
    "    m_seq, _ = valh.mask_last_msg_in_seq(m_seq, mask_i)\n",
    "    # inference\n",
    "    input = (\n",
    "        one_hot(\n",
    "            jnp.expand_dims(m_seq, axis=0), vocab_len\n",
    "        ).astype(float),\n",
    "        jnp.expand_dims(b_seq, axis=0)\n",
    "    )\n",
    "    integration_timesteps = (\n",
    "        jnp.ones((1, len(m_seq))), \n",
    "        jnp.ones((1, len(b_seq)))\n",
    "    )\n",
    "    logits = valh.predict(\n",
    "        input,\n",
    "        integration_timesteps, state, model, batchnorm)\n",
    "    if valid_mask is not None:\n",
    "        logits = valh.filter_valid_pred(logits, valid_mask)\n",
    "    # TODO: remove - just for debugging\n",
    "    label = m_enc[end_i][mask_i]\n",
    "    losses.append(cross_entropy_loss(logits, label))\n",
    "    accs.append(compute_accuracy(logits, label))\n",
    "\n",
    "    #print(m_seq[-20:])\n",
    "    # update sequence\n",
    "    # note: rng arg expects one element per batch element\n",
    "    rng, rng_ = jax.random.split(rng)\n",
    "    m_seq = valh.fill_predicted_toks(m_seq, logits, sample_top_n, jnp.array([rng_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([    8,    22,    22,     2,     2,  1003,  1107, 11107, 11008,\n",
       "       11109,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2], dtype=int32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_seq[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([ True], dtype=bool),\n",
       " Array([ True], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([ True], dtype=bool),\n",
       " Array([ True], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool),\n",
       " Array([False], dtype=bool)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([1.1188538], dtype=float32),\n",
       " Array([25.409428], dtype=float32),\n",
       " Array([31.802822], dtype=float32),\n",
       " Array([15.232959], dtype=float32),\n",
       " Array([22.315346], dtype=float32),\n",
       " Array([23.502268], dtype=float32),\n",
       " Array([28.578278], dtype=float32),\n",
       " Array([19.202412], dtype=float32),\n",
       " Array([19.152643], dtype=float32),\n",
       " Array([24.333796], dtype=float32),\n",
       " Array([0.4000675], dtype=float32),\n",
       " Array([8.457518e-05], dtype=float32),\n",
       " Array([3.1385012], dtype=float32),\n",
       " Array([2.9693208], dtype=float32),\n",
       " Array([0.05330859], dtype=float32),\n",
       " Array([0.00211861], dtype=float32),\n",
       " Array([6.8914833], dtype=float32),\n",
       " Array([7.080786], dtype=float32),\n",
       " Array([6.7107654], dtype=float32),\n",
       " Array([6.88228], dtype=float32)]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([    8,    22,    22,     2,     2,  1003,  1107, 11107, 11008,\n",
       "       11109,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2], dtype=int32)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_seq[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try multiple rolls to get valid message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# sim_msg = get_sim_msg(\n",
    "#     m_enc[end_i],\n",
    "#     m_seq,\n",
    "#     sim,\n",
    "#     tok,\n",
    "#     v,\n",
    "#     new_order_id=42, tick_size=100\n",
    "# )\n",
    "# sim_msg\n",
    "\n",
    "# sim.process_order(sim_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['005', '019', '019', 'NAN', 'NAN', '1', '010', '+', '01', '0',\n",
       "        'NAN', 'NAN', 'NAN', 'NAN', 'NAN', 'NAN', 'NAN', 'NAN', 'NAN',\n",
       "        'NAN']], dtype='<U3')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode_to_str(m_seq[-20:], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1., 10.,  1.,  0., nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode predicted message\n",
    "pred_msg = tok.decode(m_seq[-20:], v).flatten()\n",
    "pred_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('time', '019')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.DECODING_GLOBAL[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valh.validate_msg(m_seq[-20:], tok, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(987900, dtype=int32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.get_best_bid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get new order ID from simulator\n",
    "new_order_id = 42\n",
    "tick_size = 100\n",
    "\n",
    "def get_sim_msg(pred_msg_enc, m_seq, sim, tok, v, new_order_id, tick_size):\n",
    "    # decoded predicted message\n",
    "    pred_msg = tok.decode(pred_msg_enc, v).flatten()\n",
    "    \n",
    "    orig_part = pred_msg[: len(pred_msg) // 2]\n",
    "    modif_part = pred_msg[len(pred_msg) // 2:]\n",
    "\n",
    "    # new order: no modification values present (all NA)\n",
    "    # should be new limit order (1) or execution (4)\n",
    "    if onp.isnan(modif_part).all():\n",
    "        # convert relative to absolute price\n",
    "        price = sim.get_best_bid() + int(orig_part[3]) * tick_size\n",
    "        order_dict = {\n",
    "            'timestamp': str(orig_part[0] * 1e-9 + 9.5 * 3600),\n",
    "            'type': int(orig_part[1]),\n",
    "            'order_id': new_order_id, \n",
    "            'quantity': int(orig_part[2]),\n",
    "            'price': price,\n",
    "            'side': 'ask' if orig_part[4] == 0 else 'bid',  # TODO: should be 'buy' or 'sell'\n",
    "            'trade_id': 0  # should be trader_id in future\n",
    "        }\n",
    "    # modification of existing order\n",
    "    else:\n",
    "        # original part is only needed to match to an order ID\n",
    "        # find original msg index location in the sequence (if it exists)\n",
    "        orig_enc = pred_msg_enc[: len(pred_msg_enc) // 2]\n",
    "        orig_i = valh.find_orig_msg(orig_enc, m_seq)\n",
    "        if orig_i is not None:\n",
    "            # get order ID from raw data for simulator\n",
    "            order_id = int(m.iloc[orig_i].order_id)\n",
    "        else:\n",
    "            # TODO: fuzzy match??\n",
    "            #       or just assume ID unknown and match to price level only...\n",
    "            #       ... in which case - which order in the queue?\n",
    "            #       perhaps last one that matches size? (>=)\n",
    "            order_id = -1  # TODO: use simulator initial ID?\n",
    "\n",
    "        # convert relative to absolute price\n",
    "        price = sim.get_best_bid() + int(modif_part[3]) * tick_size\n",
    "        order_dict = {\n",
    "            'timestamp': str(modif_part[0] * 1e-9 + 9.5 * 3600),\n",
    "            'type': int(modif_part[1]),\n",
    "            'order_id': order_id, \n",
    "            'quantity': int(modif_part[2]),\n",
    "            'price': price,\n",
    "            'side': 'ask' if modif_part[4] == 0 else 'bid',  # TODO: should be 'buy' or 'sell'\n",
    "            'trade_id': 0  # should be trader_id in future\n",
    "        }\n",
    "\n",
    "    return order_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg_to_raw(msg, bid_price, tick_size):\n",
    "    \"\"\"Convert message to raw data format.\"\"\"\n",
    "    assert len(msg) == 5\n",
    "    # time\n",
    "    msg[0] = msg[0] * 1e-9 + 9.5 * 3600\n",
    "    # price\n",
    "    msg[3] = bid_price + int(msg[3]) * tick_size\n",
    "    # direction\n",
    "    msg[4] = msg[4] * 2 - 1\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    8,   402,   328,   183,   770,  1003,  1207, 11107, 11011,\n",
       "       11109,     8,   403,     9,   666,   752,  1005,  1107, 11107,\n",
       "       11010, 11109])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual next message (not predicted and not part of seq)\n",
    "m_enc[end_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_seq = m.iloc[end_i - n_messages: end_i].copy()\n",
    "#raw_seq.drop('order_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': '39600.006663749',\n",
       " 'type': 3,\n",
       " 'order_id': 32429970,\n",
       " 'quantity': 10,\n",
       " 'price': Array(988200, dtype=int32),\n",
       " 'side': 'ask',\n",
       " 'trade_id': 0}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_msg = get_sim_msg(\n",
    "    m_enc[end_i],\n",
    "    m_seq,\n",
    "    sim,\n",
    "    tok,\n",
    "    v,\n",
    "    new_order_id=42, tick_size=100\n",
    ")\n",
    "sim_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       5       -1       10   988200        0 32429970    39600  6663749]\n",
      "[[[[      100    988000         0 276499246     39599 322500767]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  [[      100    988100         0 276492538     39599 264867549]\n",
      "   [       82    988100         0 276511822     39599 685781583]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  [[       81    988200         0 276491886     39599  26281485]\n",
      "   [      100    988200         0 276500518     39599  33606933]\n",
      "   [      100    988200         0 276489698     39599 251200259]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[     1082    988700         0  90000000     34200         0]\n",
      "   [      100    988700         0 276476526     39599  54624969]\n",
      "   [      100    988700         0 276478378     39599  60038899]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  [[      331    988800         0  90000000     34200         0]\n",
      "   [      100    988800         0 276487218     39599 183592463]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  [[       50    989000         0 276503650     39599 423577432]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]]\n",
      "\n",
      "\n",
      " [[[      200    987900         0 276501242     39599 352490234]\n",
      "   [      100    987900         0 276501254     39599 352499189]\n",
      "   [       82    987900         0 276501258     39599 352500502]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  [[      300    987800         0  90000000     34200         0]\n",
      "   [       82    987800         0 276499738     39599 324469366]\n",
      "   [      100    987800         0 276499742     39599 324494973]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  [[      350    987700         0  90000000     34200         0]\n",
      "   [       50    987700         0 276492482     39599 264783146]\n",
      "   [      200    987700         0 276513250     39599 732674883]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[       50    987200         0 276489674     39599  25117112]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  [[       50    987100         0 276492046     39599 263796407]\n",
      "   [      100    987100         0 276499290     39599 322539612]\n",
      "   [      600    987100         0 276515962     39599 852575272]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]\n",
      "\n",
      "  [[       50    987000         0 276497914     39599 279221614]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   ...\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]\n",
      "   [       -1        -1        -1        -1        -1        -1]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([[-1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1]], dtype=int32),\n",
       " Array([       5,       -1,       10,   988200,        0, 32429970,\n",
       "           39600,  6663749], dtype=int32))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.process_order(sim_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000, 11111)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500, 41)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactor slightly and work in simulation step\n",
    "#       and simulator matching orders\n",
    "\n",
    "pred_n_messages = 1\n",
    "valid_mask_array = valh.syntax_validation_matrix()\n",
    "inf_seq = valh.pred_msg(\n",
    "    start_seq,\n",
    "    pred_n_messages,\n",
    "    state,\n",
    "    model,\n",
    "    args.batchnorm,\n",
    "    rng,\n",
    "    valid_mask_array\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
